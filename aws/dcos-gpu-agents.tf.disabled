## DC/OS GPU Private Agent
## State: Experimental
#
# This came out from an experiment to extend GPU support to DC/OS.
# You can easily add this module by removing '.disabled' 
# to the file name. You an always remove it at any time. The defaults 
# variables are managed by this sinlge file for ease of integration. 

variable "num_of_gpu_agents" {
  default = "1"
}

variable "aws_gpu_agent_instance_type" {
  default = "g2.2xlarge"
}

# AMI Zone US-WEST-2
variable "aws_gpu_ami" {
 default = "ami-9b5d97fb"
}

# AWS Resourece Agent for GPUs
resource "aws_instance" "gpu-agent" {
  # The connection block tells our provisioner how to
  # communicate with the resource (instance)
  connection {
    # The default username for our AMI
    user = "centos"

    # The connection will use the local SSH agent for authentication.
  }

  root_block_device {
    volume_size = "${var.instance_disk_size}"
  }

  count = "${var.num_of_gpu_agents}"
  instance_type = "${var.aws_gpu_agent_instance_type}"

  ebs_optimized = "true"

  tags {
   owner = "${coalesce(var.owner, data.external.whoami.result["owner"])}"
   expiration = "${var.expiration}"
   Name =  "${data.template_file.cluster-name.rendered}-gpuagt-${count.index + 1}"
   cluster = "${data.template_file.cluster-name.rendered}"
  }
  # Lookup the correct AMI based on the region
  # we specified
  ami = "${var.aws_gpu_ami}"      

  # The name of our SSH keypair we created above.
  ssh_key_name = "${var.ssh_key_name}"

  # Our Security group to allow http and SSH access
  vpc_security_group_ids = ["${aws_security_group.private_slave.id}","${aws_security_group.admin.id}","${aws_security_group.any_access_internal.id}"]

  # We're going to launch into the same subnet as our ELB. In a production
  # environment it's more common to have a separate private subnet for
  # backend instances.
  subnet_id = "${aws_subnet.private.id}"

  # OS init script
  provisioner "file" {
   source = "modules/dcos-tested-aws-oses/platform/cloud/aws/centos_7.2/setup.sh"
   destination = "/tmp/os-setup.sh"
   }

 # We run a remote provisioner on the instance after creating it.
  # In this case, we just install nginx and start it. By default,
  # this should be on port 80
    provisioner "remote-exec" {
    inline = [
      "sudo chmod +x /tmp/os-setup.sh",
      "sudo bash /tmp/os-setup.sh",
    ]
  }

  lifecycle {
    ignore_changes = ["tags.Name"]
  }
}


# Create DCOS Mesos Agent Scripts to execute
module "dcos-mesos-gpu-agent" {
  source               = "github.com/bernadinm/tf_dcos_core"
  bootstrap_private_ip = "${aws_instance.bootstrap.private_ip}"
  dcos_install_mode    = "${var.state}"
  dcos_version         = "${var.dcos_version}"
  role                 = "dcos-mesos-agent"
}


# Execute generated script on agent
resource "null_resource" "gpu-agent" {
  # Changes to any instance of the cluster requires re-provisioning
  triggers {
    cluster_instance_ids = "${null_resource.bootstrap.id}"
  }

  # Bootstrap script can run on any instance of the cluster
  # So we just choose the first in this case
  connection {
    host = "${element(aws_instance.gpu-agent.*.public_ip, count.index)}"
    user = "centos"
  }

  count = "${var.num_of_gpu_agents}"

  # Generate and upload Agent script to node
  provisioner "file" {
    content     = "${module.dcos-mesos-agent.script}"
    destination = "run.sh"
  }

  # Wait for bootstrapnode to be ready
  provisioner "remote-exec" {
    inline = [
     "until $(curl --output /dev/null --silent --head --fail http://${aws_instance.bootstrap.private_ip}/dcos_install.sh); do printf 'waiting for bootstrap node to serve...'; sleep 20; done"
    ]
  }

  # Install Slave Node
  provisioner "remote-exec" {
    inline = [
      "sudo chmod +x run.sh",
      "sudo ./run.sh",
    ]
  }
}

output "GPU Private Public IP Address" {
  value = ["${aws_instance.gpu-agent.*.public_ip}"]
}

